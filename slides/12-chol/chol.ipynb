{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cholesky Decomposition\n",
    "\n",
    "<img src=\"http://www.cerebralmastication.com/wp-content/uploads/2010/09/39-cholesky-250x300.jpg\" width=\"200\" align=\"center\"/>\n",
    "\n",
    "* A basic tenet in numerical analysis: \n",
    "\n",
    "> **The structure should be exploited whenever solving a problem.** \n",
    "\n",
    "  Common structures include: symmetry, positive (semi)definiteness, sparsity, Kronecker product, low rank, ...\n",
    "\n",
    "* LU decomposition (Gaussian Elimination) is **not** used in statistics so often because most of time statisticians deal with positive (semi)definite matrix. \n",
    "\n",
    "* That's why I often criticize use of the `solve()` function in base R code, which inverts a matrix using LU decomposition. First, most likely we don't need a matrix inverse. Second, most likely we are dealing with a pd/psd matrix and should use Cholesky.\n",
    "\n",
    "* For example, in the normal equation \n",
    "$$\n",
    "    \\mathbf{X}^T \\mathbf{X} \\beta = \\mathbf{X}^T \\mathbf{y}\n",
    "$$\n",
    "for linear regression, the coefficient matrix $\\mathbf{X}^T \\mathbf{X}$ is symmetric and positive semidefinite. How to exploit this structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cholesky decomposition\n",
    "\n",
    "* **Theorem**: Let $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ be symmetric and positive definite. Then $\\mathbf{A} = \\mathbf{L} \\mathbf{L}^T$, where $\\mathbf{L}$ is lower triangular with positive diagonal entries and is unique.  \n",
    "**Proof** (by induction):  \n",
    "If $n=1$, then $\\ell = \\sqrt{a}$. For $n>1$, the block equation\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\begin{pmatrix}\n",
    "a_{11} & \\mathbf{a}^T \\\\ \\mathbf{a} & \\mathbf{A}_{22}\n",
    "\\end{pmatrix} =\n",
    "\\begin{pmatrix}\n",
    "\t\\ell_{11} & \\mathbf{0}_{n-1}^T \\\\ \\mathbf{l} & \\mathbf{L}_{22}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\t\\ell_{11} & \\mathbf{l}^T \\\\ \\mathbf{0}_{n-1} & \\mathbf{L}_{22}^T\n",
    "\\end{pmatrix}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "has solution\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\t\\ell_{11} &=& \\sqrt{a_{11}} \\\\\n",
    "\t\\mathbf{l} &=& \\ell_{11}^{-1} \\mathbf{a}\t\\\\\n",
    "\t\\mathbf{L}_{22} \\mathbf{L}_{22}^T &=& \\mathbf{A}_{22}  - \\mathbf{l} \\mathbf{l}^T = \\mathbf{A}_{22}  - a_{11}^{-1} \\mathbf{a} \\mathbf{a}^T.\n",
    "\\end{eqnarray*}\n",
    "$$  \n",
    "Now $a_{11}>0$ (why?), so $\\ell_{11}$ and $\\mathbf{l}$ are uniquely determined. $\\mathbf{A}_{22} - a_{11}^{-1} \\mathbf{a} \\mathbf{a}^T$ is positive definite because $\\mathbf{A}$ is positive definite (why?). By induction hypothesis, $\\mathbf{L}_{22}$ exists and is unique.\n",
    "\n",
    "* The constructive proof completely specifies the algorithm: \n",
    "\n",
    "<img src=\"http://www.netlib.org/utk/papers/factor/_25826_figure440.gif\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "* Computational cost: \n",
    "$$\n",
    "\\frac{1}{2} [2(n-1)^2 + 2(n-2)^2 + \\cdots + 2 \\cdot 1^2] \\approx \\frac{1}{3} n^3 \\quad \\text{flops}\n",
    "$$ \n",
    "plus $n$ square roots. Half the cost of LU decomposition by utilizing symmetry.\n",
    "\n",
    "* In general Cholesky decomposition is very stable. Failure of the decomposition simply means $\\mathbf{A}$ is not positive definite. It is an efficient way to test positive definiteness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting\n",
    "\n",
    "* When $\\mathbf{A}$ does not have full rank, e.g., $\\mathbf{X}^T \\mathbf{X}$ with a non-full column rank $\\mathbf{X}$, we encounter $a_{kk} = 0$ during the procedure.\n",
    "\n",
    "* **Symmetric pivoting**. At each stage $k$, we permute both row and column such that $\\max_{k \\le i \\le n} a_{ii}$ becomes the pivot. If we encounter $\\max_{k \\le i \\le n} a_{ii} = 0$, then $\\mathbf{A}[k:n,k:n] = \\mathbf{0}$ (why?) and the algorithm terminates.\n",
    "\n",
    "* With symmetric pivoting: \n",
    "$$\n",
    "\\mathbf{P} \\mathbf{A} \\mathbf{P}^T = \\mathbf{L} \\mathbf{L}^T,\n",
    "$$\n",
    "where $\\mathbf{P}$ is a permutation matrix and $\\mathbf{L} \\in \\mathbb{R}^{n \\times r}$, $r = \\text{rank}(\\mathbf{A})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAPACK and Julia implementation\n",
    "\n",
    "* LAPACK functions: [?potrf](http://www.netlib.org/lapack/explore-html/d1/d7a/group__double_p_ocomputational_ga2f55f604a6003d03b5cd4a0adcfb74d6.html#ga2f55f604a6003d03b5cd4a0adcfb74d6) (without pivoting), [?pstrf](http://www.netlib.org/lapack/explore-html/da/dba/group__double_o_t_h_e_rcomputational_ga31cdc13a7f4ad687f4aefebff870e1cc.html#ga31cdc13a7f4ad687f4aefebff870e1cc) (with pivoting).\n",
    "\n",
    "* Julia functions: [cholesky](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.cholesky), [cholesky!](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.cholesky!), or call LAPACK wrapper functions [potrf!](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.LAPACK.potrf!) and [pstrf!](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.LAPACK.pstrf!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: positive definite matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "A = [4.0 12 -16; 12 37 -43; -16 -43 98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cholesky without pivoting\n",
    "Achol = cholesky(Symmetric(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(Achol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(Achol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the lower triangular Cholesky factor\n",
    "Achol.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the upper triangular Cholesky factor\n",
    "Achol.U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [1.0; 2.0; 3.0]\n",
    "A \\ b # this does LU; wasteful!!!; 2/3 n^3 + 2n^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Achol \\ b # two triangular solves; only 2n^2 flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det(A) # this does LU; wasteful!!! (2/3) n^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det(Achol) # cheap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv(A) # this does LU! (2/3) n^3 + (4/3) n^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv(Achol) # (4/3) n^3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: positive semi-definite matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "\n",
    "Random.seed!(123) # seed\n",
    "A = randn(5, 3)\n",
    "A = A * transpose(A) # A has rank 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Achol = cholesky(A, Val(true)) # 2nd argument requests pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Achol = cholesky(A, Val(true), check=false) # turn off checking pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank(Achol) # determine rank from Cholesky factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank(A) # determine rank from SVD (default), which is more numerically stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Achol.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Achol.U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Achol.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P A P' = L U\n",
    "A[Achol.p, Achol.p] ≈ Achol.L * Achol.U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications\n",
    "\n",
    "* **No inversion** mentality: Whenever we see matrix inverse, we should think in terms of solving linear equations. If the matrix is positive (semi)definite, use Cholesky decomposition, which is twice cheaper than LU decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate normal density \n",
    "\n",
    "Multivariate normal density $\\text{MVN}(0, \\Sigma)$, where $\\Sigma$ is p.d., is\n",
    "$$\n",
    "\\, - \\frac{n}{2} \\log (2\\pi) - \\frac{1}{2} \\log \\det \\Sigma - \\frac{1}{2} \\mathbf{y}^T \\Sigma^{-1} \\mathbf{y}.\n",
    "$$\n",
    "\n",
    "* **Method 1**: (a) compute explicit inverse $\\Sigma^{-1}$ ($2n^3$ flops), (b) compute quadratic form ($2n^2 + 2n$ flops), (c) compute determinant ($2n^3/3$ flops).\n",
    "    \n",
    "* **Method 2**: (a) Cholesky decomposition $\\Sigma = \\mathbf{L} \\mathbf{L}^T$ ($n^3/3$ flops), (b) Solve $\\mathbf{L} \\mathbf{x} = \\mathbf{y}$ by forward substitutions ($n^2$ flops), (c) compute quadratic form $\\mathbf{x}^T \\mathbf{x}$ ($2n$ flops), and (d) compute determinant from Cholesky factor ($n$ flops).  \n",
    "\n",
    "**Which method is better?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a person w/o numerical analysis training\n",
    "function logpdf_mvn_1(y::Vector, Σ::Matrix)\n",
    "    n = length(y)\n",
    "    - (n//2) * log(2π) - (1//2) * logdet(Symmetric(Σ)) - (1//2) * transpose(y) * inv(Σ) * y\n",
    "end\n",
    "\n",
    "# this is a computing-savvy person \n",
    "function logpdf_mvn_2(y::Vector, Σ::Matrix)\n",
    "    n = length(y)\n",
    "    Σchol = cholesky(Symmetric(Σ))\n",
    "    - (n//2) * log(2π) - (1//2) * logdet(Σchol) - (1//2) * abs2(norm(Σchol.L \\ y))\n",
    "end\n",
    "\n",
    "# better memory efficiency - input Σ is overwritten\n",
    "function logpdf_mvn_3(y::Vector, Σ::Matrix)\n",
    "    n = length(y)\n",
    "    Σchol = cholesky!(Symmetric(Σ)) # Σ is overwritten\n",
    "    - (n//2) * log(2π) - (1//2) * logdet(Σchol) - (1//2) * dot(y, Σchol \\ y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools, Distributions, Random\n",
    "\n",
    "Random.seed!(123) # seed\n",
    "\n",
    "n = 1000\n",
    "# a pd matrix\n",
    "Σ = convert(Matrix{Float64}, Symmetric([i * (n - j + 1) for i in 1:n, j in 1:n]))\n",
    "y = rand(MvNormal(Σ)) # one random sample from N(0, Σ)\n",
    "\n",
    "# at least they should give the same answer\n",
    "@show logpdf_mvn_1(y, Σ)\n",
    "@show logpdf_mvn_2(y, Σ)\n",
    "Σc = copy(Σ)\n",
    "@show logpdf_mvn_3(y, Σc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark logpdf_mvn_1($y, $Σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark logpdf_mvn_2($y, $Σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark logpdf_mvn_3($y, $Σc) setup=(copy!(Σc, Σ)) evals=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To evaluate same multivariate normal density at many observations $y_1, y_2, \\ldots$, we pre-compute the Cholesky decomposition ($n^3/3$ flops), then each evaluation costs $n^2$ flops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "- Cholesky decomposition is **one** approach to solve linear regression  \n",
    "$$\n",
    "\\widehat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}.\n",
    "$$\n",
    "\n",
    "- Assume $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ and $\\mathbf{y} \\in \\mathbb{R}^n$.  \n",
    "    - Compute $\\mathbf{X}^T \\mathbf{X}$: $np^2$ flops  \n",
    "    - Compute $\\mathbf{X}^T \\mathbf{y}$: $2np$ flops  \n",
    "    - Cholesky decomposition of $\\mathbf{X}^T \\mathbf{X}$: $\\frac{1}{3} p^3$ flops  \n",
    "    - Solve normal equation $\\mathbf{X}^T \\mathbf{X} \\beta = \\mathbf{X}^T \\mathbf{y}$: $2p^2$ flops  \n",
    "    - If need standard errors, another $(4/3)p^3$ flops\n",
    "\n",
    "- Total computational cost is $np^2 + (1/3) p^3$ (without s.e.) or $np^2 + (5/3) p^3$ (with s.e.) flops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "* Section 7.7 of [Numerical Analysis for Statisticians](http://ucla.worldcat.org/title/numerical-analysis-for-statisticians/oclc/793808354&referer=brief_results) of Kenneth Lange (2010).\n",
    "\n",
    "* Section II.5.3 of [Computational Statistics](http://ucla.worldcat.org/title/computational-statistics/oclc/437345409&referer=brief_results) by James Gentle (2010).\n",
    "\n",
    "* Section 4.2 of [Matrix Computation](http://catalog.library.ucla.edu/vwebv/holdingsInfo?bibId=7122088) by Gene Golub and Charles Van Loan (2013)."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "118px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
